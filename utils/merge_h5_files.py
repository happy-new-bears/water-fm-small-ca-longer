"""
å°†æŒ‰æœˆåˆ†å‰²çš„h5æ–‡ä»¶åˆå¹¶ä¸ºæŒ‰train/valåˆ†å‰²çš„å¤§æ–‡ä»¶

ä¼˜ç‚¹ï¼š
1. å‡å°‘æ–‡ä»¶æ‰“å¼€æ¬¡æ•°ï¼ˆä»~264ä¸ªæ–‡ä»¶ -> 1ä¸ªæ–‡ä»¶ï¼‰
2. è¿ç»­å­˜å‚¨ï¼Œæ”¯æŒé«˜æ•ˆåˆ‡ç‰‡
3. å¯ä»¥ç›´æ¥ç¼“å­˜åˆ°å†…å­˜

ä½¿ç”¨æ–¹æ³•ï¼š
    python utils/merge_h5_files.py
"""

import h5py
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
from tqdm import tqdm
import os


def merge_h5_files_by_period(
    input_dir: str,
    output_dir: str,
    modality_name: str,
    start_date: str,
    end_date: str,
    period_name: str  # 'train' or 'val'
):
    """
    å°†æŒ‡å®šæ—¶é—´æ®µçš„h5æ–‡ä»¶åˆå¹¶ä¸ºå•ä¸ªæ–‡ä»¶

    Args:
        input_dir: è¾“å…¥ç›®å½•ï¼Œå¦‚ '/path/to/precipitation_processed'
        output_dir: è¾“å‡ºç›®å½•
        modality_name: æ¨¡æ€åç§°ï¼Œå¦‚ 'precipitation'
        start_date: å¼€å§‹æ—¥æœŸ 'YYYY-MM-DD'
        end_date: ç»“æŸæ—¥æœŸ 'YYYY-MM-DD'
        period_name: æ—¶æœŸåç§° 'train' or 'val'
    """

    input_path = Path(input_dir)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨
    start = datetime.strptime(start_date, '%Y-%m-%d')
    end = datetime.strptime(end_date, '%Y-%m-%d')

    date_list = []
    current = start
    while current <= end:
        date_list.append(current)
        current += timedelta(days=1)

    num_days = len(date_list)
    print(f"\n{'='*60}")
    print(f"Merging {modality_name} - {period_name}")
    print(f"{'='*60}")
    print(f"Date range: {start_date} to {end_date}")
    print(f"Total days: {num_days}")

    # è¯»å–ç¬¬ä¸€ä¸ªæ ·æœ¬è·å–shape
    first_date = date_list[0]
    first_file = input_path / f"{modality_name}_{first_date.strftime('%Y_%m')}.h5"

    with h5py.File(first_file, 'r') as f:
        first_key = first_date.strftime('%Y-%m-%d')
        sample_shape = f[first_key].shape
        sample_dtype = f[first_key].dtype

    print(f"Image shape: {sample_shape}")
    print(f"Image dtype: {sample_dtype}")

    H, W = sample_shape
    total_size_gb = num_days * H * W * 4 / (1024**3)
    print(f"Estimated output size: {total_size_gb:.2f} GB")

    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶
    output_file = output_path / f"{modality_name}_{period_name}_{start_date[:4]}_{end_date[:4]}.h5"

    print(f"\nWriting to: {output_file}")
    print("This may take a few minutes...")

    with h5py.File(output_file, 'w') as f_out:
        # åˆ›å»ºdatasetï¼ˆä½¿ç”¨chunkingå’Œcompressionï¼‰
        data_ds = f_out.create_dataset(
            'data',
            shape=(num_days, H, W),
            dtype=sample_dtype,
            chunks=(30, H, W),  # æ¯30å¤©ä¸€ä¸ªchunkï¼Œæ–¹ä¾¿åºåˆ—è¯»å–
            compression='gzip',
            compression_opts=4,  # ä¸­ç­‰å‹ç¼©çº§åˆ«ï¼ˆ1-9ï¼‰
        )

        # åˆ›å»ºæ—¥æœŸç´¢å¼•ï¼ˆå­˜å‚¨ä¸ºå­—ç¬¦ä¸²ï¼‰
        date_strings = [d.strftime('%Y-%m-%d') for d in date_list]
        f_out.create_dataset(
            'dates',
            data=np.array(date_strings, dtype='S10')  # å›ºå®šé•¿åº¦å­—ç¬¦ä¸²
        )

        # æŒ‰æœˆè¯»å–å¹¶å†™å…¥
        current_month = None
        f_in = None

        for day_idx, date in enumerate(tqdm(date_list, desc="Processing")):
            year_month = date.strftime('%Y-%m')

            # å¦‚æœæ˜¯æ–°æœˆä»½ï¼Œæ‰“å¼€æ–°æ–‡ä»¶
            if year_month != current_month:
                if f_in is not None:
                    f_in.close()

                input_file = input_path / f"{modality_name}_{date.strftime('%Y_%m')}.h5"

                if not input_file.exists():
                    print(f"\nWarning: File not found: {input_file}")
                    print(f"Filling with zeros for {date.strftime('%Y-%m-%d')}")
                    data_ds[day_idx] = np.zeros((H, W), dtype=sample_dtype)
                    continue

                f_in = h5py.File(input_file, 'r')
                current_month = year_month

            # è¯»å–æ•°æ®
            date_key = date.strftime('%Y-%m-%d')

            if date_key in f_in:
                data_ds[day_idx] = f_in[date_key][:]
            else:
                print(f"\nWarning: Date {date_key} not found in file")
                data_ds[day_idx] = np.zeros((H, W), dtype=sample_dtype)

        if f_in is not None:
            f_in.close()

    # éªŒè¯è¾“å‡ºæ–‡ä»¶
    actual_size_mb = os.path.getsize(output_file) / (1024**2)
    print(f"\nâœ“ Successfully created: {output_file}")
    print(f"âœ“ Actual file size: {actual_size_mb:.2f} MB")
    print(f"âœ“ Compression ratio: {total_size_gb * 1024 / actual_size_mb:.1f}x")


def main():
    """ä¸»å‡½æ•°ï¼šåˆå¹¶æ‰€æœ‰æ¨¡æ€çš„h5æ–‡ä»¶"""

    # é…ç½®
    data_root = '/Users/transformer/Desktop/water_data/new_version'
    output_root = data_root  # ç›´æ¥è¾“å‡ºåˆ°åŸæ•°æ®ç›®å½•

    # æ¨¡æ€åˆ—è¡¨
    modalities = {
        'precipitation': 'precipitation_processed',
        'soil_moisture': 'soil_moisture_processed',
        'temperature': 'temperature_processed',
    }

    # æ—¶é—´æ®µé…ç½®
    periods = {
        'train': ('1989-01-01', '2010-12-31'),
        'val': ('2011-01-01', '2015-12-30'),
    }

    print("="*60)
    print("H5 File Merger for Multi-modal Hydrology Data")
    print("="*60)
    print(f"Input root: {data_root}")
    print(f"Output root: {output_root}")
    print(f"Modalities: {list(modalities.keys())}")
    print(f"Periods: {list(periods.keys())}")

    # åˆå¹¶æ¯ä¸ªæ¨¡æ€çš„æ¯ä¸ªæ—¶æœŸ
    for modality_name, input_subdir in modalities.items():
        input_dir = f"{data_root}/{input_subdir}"

        # æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not Path(input_dir).exists():
            print(f"\nWarning: Directory not found: {input_dir}")
            print("Skipping...")
            continue

        for period_name, (start_date, end_date) in periods.items():
            try:
                merge_h5_files_by_period(
                    input_dir=input_dir,
                    output_dir=output_root,
                    modality_name=modality_name,
                    start_date=start_date,
                    end_date=end_date,
                    period_name=period_name
                )
            except Exception as e:
                print(f"\nâœ— Error processing {modality_name} {period_name}: {e}")
                import traceback
                traceback.print_exc()
                continue

    print("\n" + "="*60)
    print("âœ“âœ“âœ“ All files merged successfully!")
    print("="*60)
    print(f"\nMerged files are in: {output_root}")
    print("\nNext steps:")
    print("1. Update your config to use the new merged files")
    print("2. Update MultiModalHydroDataset to use the merged format")
    print("3. Enjoy 10-100x faster data loading! ğŸš€")


if __name__ == '__main__':
    main()
